{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost requests pandas numpy datetime scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5TTIokYPRRn",
        "outputId": "783fa6bb-a03e-4794-c362-a7792378230c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xgboost\n",
            "  Using cached xgboost-2.1.3-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Collecting datetime\n",
            "  Using cached DateTime-5.5-py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Collecting nvidia-nccl-cu12 (from xgboost)\n",
            "  Downloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Collecting zope.interface (from datetime)\n",
            "  Downloading zope.interface-7.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zope.interface->datetime) (75.1.0)\n",
            "Downloading xgboost-2.1.3-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading DateTime-5.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl (199.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/199.0 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zope.interface-7.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (254 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.5/254.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: zope.interface, nvidia-nccl-cu12, xgboost, datetime\n",
            "Successfully installed datetime-5.5 nvidia-nccl-cu12-2.23.4 xgboost-2.1.3 zope.interface-7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAAbNYc4FmPQ",
        "outputId": "dc731331-6d3a-46dc-9b1f-eec2504c1507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RMSE: 0.3067435316325371\n",
            "        date  predicted_fuel_price\n",
            "0 2024-12-20              2.566265\n",
            "1 2024-12-21              2.566265\n",
            "2 2024-12-22              2.566265\n",
            "3 2024-12-23              2.566265\n",
            "4 2024-12-24              2.566265\n",
            "5 2024-12-25              2.566265\n",
            "6 2024-12-26              2.566265\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "############################################################\n",
        "# Revised code to avoid issues with older XGBoost versions:\n",
        "#\n",
        "# Changes made:\n",
        "#  - Removed `early_stopping_rounds` and `eval_set` from model.fit()\n",
        "#    as some older versions of XGBoost do not support these arguments.\n",
        "#  - Removed passing eval_metric and verbose to fit. Instead, we rely on\n",
        "#    default parameters and do our own evaluation after training.\n",
        "#  - Removed deprecated `fillna(method='...')`, using `ffill()` and `bfill()`.\n",
        "#\n",
        "# This code:\n",
        "# 1. Generates synthetic (dummy) data for a variety of factors.\n",
        "# 2. Creates lag features.\n",
        "# 3. Trains an XGBoost model using time series split.\n",
        "# 4. Selects the best model based on RMSE.\n",
        "# 5. Forecasts for a future 7-day window (with dummy stable conditions).\n",
        "#\n",
        "# Note: This is a conceptual demonstration, not a production solution.\n",
        "############################################################\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "########################\n",
        "# Configuration Section\n",
        "########################\n",
        "\n",
        "END_DATE = datetime.date.today()\n",
        "START_DATE = END_DATE - datetime.timedelta(days=365)\n",
        "date_range = pd.date_range(start=START_DATE, end=END_DATE, freq='D')\n",
        "N = len(date_range)\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "########################\n",
        "# Generate Dummy Data\n",
        "########################\n",
        "\n",
        "def generate_dummy_df(dates, col_name, mean, std):\n",
        "    return pd.DataFrame({\n",
        "        'date': dates,\n",
        "        col_name: np.random.normal(mean, std, size=len(dates))\n",
        "    })\n",
        "\n",
        "# Geological/Environmental:\n",
        "eq_df = pd.DataFrame({\n",
        "    'date': date_range,\n",
        "    'eq_count': np.random.poisson(lam=2, size=N),\n",
        "    'eq_mean_magnitude': np.random.normal(3, 0.5, size=N)\n",
        "})\n",
        "soil_moisture_df = generate_dummy_df(date_range, 'soil_moisture', mean=0.25, std=0.05)\n",
        "frost_df = generate_dummy_df(date_range, 'frost_depth', mean=0.1, std=0.05)\n",
        "stream_df = generate_dummy_df(date_range, 'stream_flow', mean=500, std=50)\n",
        "\n",
        "# Infrastructure:\n",
        "rail_df = generate_dummy_df(date_range, 'rail_capacity', mean=1000, std=100)\n",
        "port_df = generate_dummy_df(date_range, 'port_congestion_index', mean=50, std=10)\n",
        "grid_df = generate_dummy_df(date_range, 'grid_stability', mean=0.95, std=0.02)\n",
        "maintenance_df = pd.DataFrame({\n",
        "    'date': date_range,\n",
        "    'planned_outages_count': np.random.poisson(lam=1, size=N)\n",
        "})\n",
        "\n",
        "# Market Indicators:\n",
        "futures_df = generate_dummy_df(date_range, 'futures_volume', mean=10000, std=2000)\n",
        "currency_df = generate_dummy_df(date_range, 'currency_strength_index', mean=1.0, std=0.05)\n",
        "storage_df = generate_dummy_df(date_range, 'storage_level', mean=5000, std=500)\n",
        "refinery_df = generate_dummy_df(date_range, 'refinery_utilization', mean=0.85, std=0.05)\n",
        "\n",
        "# Target Fuel Price:\n",
        "fuel_prices_df = generate_dummy_df(date_range, 'fuel_price', mean=2.5, std=0.3)\n",
        "\n",
        "########################\n",
        "# Merge All Data\n",
        "########################\n",
        "\n",
        "dfs = [\n",
        "    eq_df, soil_moisture_df, frost_df, stream_df, rail_df, port_df, grid_df,\n",
        "    maintenance_df, futures_df, currency_df, storage_df, refinery_df\n",
        "]\n",
        "\n",
        "master_df = pd.DataFrame({'date': date_range})\n",
        "for d in dfs:\n",
        "    master_df = pd.merge(master_df, d, on='date', how='left')\n",
        "\n",
        "master_df = pd.merge(master_df, fuel_prices_df, on='date', how='left')\n",
        "\n",
        "# Fill missing values\n",
        "master_df = master_df.ffill().bfill()\n",
        "\n",
        "# Ensure we have target\n",
        "master_df = master_df.dropna(subset=['fuel_price'])\n",
        "\n",
        "########################\n",
        "# Feature Engineering\n",
        "########################\n",
        "\n",
        "def create_lag_features(df, cols, lags=[1,7,30]):\n",
        "    for c in cols:\n",
        "        for l in lags:\n",
        "            df[f'{c}_lag{l}'] = df[c].shift(l)\n",
        "    return df\n",
        "\n",
        "feature_cols = [c for c in master_df.columns if c not in ['date','fuel_price']]\n",
        "master_df = create_lag_features(master_df, feature_cols)\n",
        "master_df = master_df.dropna()\n",
        "\n",
        "X = master_df.drop(columns=['date','fuel_price'])\n",
        "y = master_df['fuel_price']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "########################\n",
        "# Modeling & Training\n",
        "########################\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "best_rmse = float('inf')\n",
        "best_model = None\n",
        "\n",
        "# Since older versions of XGBoost might not accept early_stopping_rounds\n",
        "# or eval_set, we train simply and evaluate ourselves.\n",
        "for train_idx, test_idx in tscv.split(X_scaled):\n",
        "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    model = xgb.XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42)\n",
        "    model.fit(X_train, y_train)  # No eval_set or early_stopping_rounds\n",
        "    y_pred = model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    if rmse < best_rmse:\n",
        "        best_rmse = rmse\n",
        "        best_model = model\n",
        "\n",
        "print(\"Best RMSE:\", best_rmse)\n",
        "\n",
        "########################\n",
        "# Forecasting\n",
        "########################\n",
        "\n",
        "future_dates = pd.date_range(start=END_DATE + datetime.timedelta(days=1), periods=7, freq='D')\n",
        "future_df = pd.DataFrame({'date': future_dates})\n",
        "\n",
        "# For demonstration, we assume no new data changes and reuse last known state\n",
        "last_known = master_df.iloc[-1:].copy()\n",
        "\n",
        "predictions = []\n",
        "current_state = last_known.copy()\n",
        "\n",
        "for future_date in future_dates:\n",
        "    current_row = current_state.drop(columns=['date','fuel_price']).copy()\n",
        "    current_row_df = pd.DataFrame(current_row.values, columns=current_row.columns)\n",
        "    current_row_scaled = scaler.transform(current_row_df)\n",
        "\n",
        "    pred_price = best_model.predict(current_row_scaled)[0]\n",
        "    predictions.append({'date': future_date, 'predicted_fuel_price': pred_price})\n",
        "\n",
        "    new_day = current_state.iloc[-1:].copy()\n",
        "    new_day['date'] = future_date\n",
        "    new_day['fuel_price'] = pred_price\n",
        "    # Not realistically updating lag features, but in a real pipeline you would.\n",
        "    current_state = pd.concat([current_state, new_day], ignore_index=True)\n",
        "\n",
        "pred_df = pd.DataFrame(predictions)\n",
        "print(pred_df)\n"
      ]
    }
  ]
}